{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e64a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys, os\n",
    "import re\n",
    "import json, requests\n",
    "\n",
    "\n",
    "def find_css(css_selector, browser):\n",
    "    return browser.find_element(By.CSS_SELECTOR, css_selector)\n",
    "def finds_css(css_selector, browser):\n",
    "    return browser.find_elements(By.CSS_SELECTOR, css_selector)\n",
    "\n",
    "def find_xpath(xpath, browser):\n",
    "    return browser.find_element(By.XPATH, xpath)\n",
    "def finds_xpath(xpath, browser):\n",
    "    return browser.find_elements(By.XPATH, xpath)\n",
    "\n",
    "def find_id(e_id, browser):\n",
    "    return browser.find_element(By.ID, e_id)\n",
    "\n",
    "def find_className(cn, browser):\n",
    "    return browser.find_element(By.CLASS_NAME, cn)\n",
    "def finds_className(cn , browser):\n",
    "    return browser.find_elements(By.CLASS_NAME, cn)\n",
    "\n",
    "def find_linktext(lt, browser):\n",
    "    return browser.find_element(By.LINK_TEXT, lt)\n",
    "\n",
    "def find_name(name, browser):\n",
    "    return browser.find_element(By.NAME, name)\n",
    "def finds_name(name, browser):\n",
    "    return browser.find_elements(By.NAME, name)\n",
    "\n",
    "def find_tagName(tag_name, browser):\n",
    "    return browser.find_element(By.TAG_NAME, tag_name)\n",
    "\n",
    "def finds_tagName(tag_name, browser):\n",
    "    return browser.find_elements(By.TAG_NAME, tag_name)\n",
    "\n",
    "def resource_path(relative_path):\n",
    "    \"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\n",
    "    base_path = getattr(sys, '_MEIPASS', os.path.dirname(os.path.abspath(__file__)))\n",
    "    return os.path.join(base_path, relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adacbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_browser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no--sandbox')\n",
    "    options.add_argument('no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-suage')\n",
    "    options.add_argument('--window-size=1080,800')\n",
    "    options.add_argument('incognito')\n",
    "    chrome_service = Service('chromedriver')\n",
    "    chrome_service = Service(executable_path='chromedriver.exe')\n",
    "    \n",
    "    browser = webdriver.Chrome(service=chrome_service, options=options)\n",
    "    \n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f26a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(browser, url):\n",
    "    browser.get(url)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d719f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('전국_상장회사_data.xlsx', 'seoul_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466dc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = df['홈페이지'].to_list()\n",
    "company_name_list = df['회사명'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9352b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_url(browser ,url_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f62b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "count = 0\n",
    "\n",
    "for url, company_name in zip(url_list, company_name_list):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BS(response.content, 'html.parser')\n",
    "\n",
    "        page_text = soup.get_text()\n",
    "\n",
    "        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "\n",
    "        email_formats = re.findall(email_pattern, page_text)\n",
    "\n",
    "        data[f'{company_name}'] = []\n",
    "        for email in email_formats:\n",
    "            data[f'{company_name}'].append({\n",
    "                email\n",
    "            })\n",
    "        count += 1\n",
    "        print(count)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96efeb",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00359cc4",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af883f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "email_formats = re.findall(email_pattern, page_text)\n",
    "\n",
    "for email in email_formats:\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78180dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = browser.window_handles\n",
    "\n",
    "for i in main:\n",
    "    if i != main[0]:\n",
    "        browser.switch_to.window(i)\n",
    "        browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3612c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jnb@jnbeng.com\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c187982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(주)제이엔비 17708 경기도 평택시 진위면 진위2산단로 31-21\n",
      "TEL. 031)8015-2001    FAX. 031)8015-2005    MAIL. jnb@jnbeng.com\n",
      "\n",
      "COPYRIGHT 2021⒞ JNB, ALL RIGHTS RESERVED.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup = BS(browser.page_source, 'html.parser')\n",
    "\n",
    "footer_text = soup.find('footer').get_text() if soup.find('footer') else None\n",
    "print(footer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd4a427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(주)제이엔비 17708 경기도 평택시 진위면 진위2산단로 31-21\n",
      "TEL. 031)8015-2001    FAX. 031)8015-2005    MAIL. jnb@jnbeng.com\n",
      "\n",
      "COPYRIGHT 2021⒞ JNB, ALL RIGHTS RESERVED.\n",
      "\n",
      "\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=121.0.6167.161)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6B64A5E42+3538674]\n\t(No symbol) [0x00007FF6B60C4C02]\n\t(No symbol) [0x00007FF6B5F75AEB]\n\t(No symbol) [0x00007FF6B5F5288C]\n\t(No symbol) [0x00007FF6B5FE5DD7]\n\t(No symbol) [0x00007FF6B5FFB40F]\n\t(No symbol) [0x00007FF6B5FDEE53]\n\t(No symbol) [0x00007FF6B5FAF514]\n\t(No symbol) [0x00007FF6B5FB0631]\n\tGetHandleVerifier [0x00007FF6B64D6CAD+3738973]\n\tGetHandleVerifier [0x00007FF6B652C506+4089270]\n\tGetHandleVerifier [0x00007FF6B6524823+4057299]\n\tGetHandleVerifier [0x00007FF6B61F5C49+720121]\n\t(No symbol) [0x00007FF6B60D126F]\n\t(No symbol) [0x00007FF6B60CC304]\n\t(No symbol) [0x00007FF6B60CC432]\n\t(No symbol) [0x00007FF6B60BBD04]\n\tBaseThreadInitThunk [0x00007FFECD217344+20]\n\tRtlUserThreadStart [0x00007FFECE4426B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m url_list:\n\u001b[0;32m      4\u001b[0m     get_url(browser, url)\n\u001b[1;32m----> 5\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BS(browser\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     footer_text \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfooter\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text() \u001b[38;5;28;01mif\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfooter\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(footer_text)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:448\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpage_source\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m            driver.page_source\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET_PAGE_SOURCE)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=121.0.6167.161)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6B64A5E42+3538674]\n\t(No symbol) [0x00007FF6B60C4C02]\n\t(No symbol) [0x00007FF6B5F75AEB]\n\t(No symbol) [0x00007FF6B5F5288C]\n\t(No symbol) [0x00007FF6B5FE5DD7]\n\t(No symbol) [0x00007FF6B5FFB40F]\n\t(No symbol) [0x00007FF6B5FDEE53]\n\t(No symbol) [0x00007FF6B5FAF514]\n\t(No symbol) [0x00007FF6B5FB0631]\n\tGetHandleVerifier [0x00007FF6B64D6CAD+3738973]\n\tGetHandleVerifier [0x00007FF6B652C506+4089270]\n\tGetHandleVerifier [0x00007FF6B6524823+4057299]\n\tGetHandleVerifier [0x00007FF6B61F5C49+720121]\n\t(No symbol) [0x00007FF6B60D126F]\n\t(No symbol) [0x00007FF6B60CC304]\n\t(No symbol) [0x00007FF6B60CC432]\n\t(No symbol) [0x00007FF6B60BBD04]\n\tBaseThreadInitThunk [0x00007FFECD217344+20]\n\tRtlUserThreadStart [0x00007FFECE4426B1+33]\n"
     ]
    }
   ],
   "source": [
    "browser = open_browser()\n",
    "\n",
    "for url in url_list:\n",
    "    get_url(browser, url)\n",
    "    soup = BS(browser.page_source, 'html.parser')\n",
    "\n",
    "    footer_text = soup.find('footer').get_text() if soup.find('footer') else None\n",
    "    print(footer_text)\n",
    "    print('--' * 20)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a98ad",
   "metadata": {},
   "source": [
    "footer을 가져오는 것은 None가 너무 많이 발생해 Pass\n",
    "다른 방안을 고안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40813c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_url(browser ,url_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "10b4a8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'스톰테크'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbafbe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TEL. 031)8015-2001\\xa0\\xa0\\xa0\\xa0FAX. 031)8015-2005\\xa0\\xa0\\xa0\\xa0MAIL. jnb@jnbeng.com']\n",
      "['TEL. 031)8015-2001\\xa0\\xa0\\xa0\\xa0FAX. 031)8015-2005\\xa0\\xa0\\xa0\\xa0MAIL. jnb@jnbeng.com']\n"
     ]
    }
   ],
   "source": [
    "soup = BS(browser.page_source, 'html.parser')\n",
    "\n",
    "# \"@\"이 포함된 텍스트만 출력\n",
    "# 정규식 패턴\n",
    "email_pattern = re.compile(r'^[a-zA-Z0-9+-_.]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n",
    "email_pattern2 = re.compile(r'^.*[a-zA-Z0-9+-_.]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n",
    "\n",
    "elements = soup.get_text()\n",
    "elements = elements.split('\\n')\n",
    "\n",
    "data = {}\n",
    "\n",
    "\n",
    "for i in elements:\n",
    "    matches = re.findall(email_pattern2, i)\n",
    "    if len(matches) >= 1:\n",
    "        print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae92396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_email_info(company, email):\n",
    "    try:\n",
    "        with open('email_info.json', 'r', encoding='utf-8') as json_file:\n",
    "            email_info = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        # 파일이 없는 경우 초기화\n",
    "        email_info = {}\n",
    "\n",
    "    # 기존 정보에 새로운 정보 추가\n",
    "    email_info[company] = email\n",
    "\n",
    "    # JSON 형식으로 저장\n",
    "    with open('email_info.json', 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(email_info, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f'{company}의 이메일 정보가 추가되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffaa130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "browser = open_browser()\n",
    "\n",
    "for url, company_name in zip(url_list, company_name_list):\n",
    "    try:\n",
    "        get_url(browser, url)\n",
    "\n",
    "        soup = BS(browser.page_source, 'html.parser')\n",
    "\n",
    "        # \"@\"이 포함된 텍스트만 출력\n",
    "        # 정규식 패턴\n",
    "        email_pattern = re.compile(r'^[a-zA-Z0-9+-_.]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n",
    "        email_pattern2 = re.compile(r'^.*[a-zA-Z0-9+-_.]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n",
    "\n",
    "        elements = soup.get_text()\n",
    "        elements = elements.split('\\n')\n",
    "\n",
    "        data = {}\n",
    "\n",
    "\n",
    "        for i in elements:\n",
    "            matches = re.findall(email_pattern2, i)\n",
    "            if len(matches) >= 1:\n",
    "                email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "                emails = re.findall(email_pattern, matches[0])\n",
    "                add_email_info(company, emails)\n",
    "#                 print(f\"{company_name}: {emails}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1adcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = ['Robots for Every Workplace쉽고 경제적인 협동로봇으로 안전하고 편리한 자동화를 선도합니다.Neuromeka.협동로봇의 다양한 활용을 통해 제조공정의 생산성 향상, F&B 서비스의 안정성 확대 그리고 문화예술 산업의 새로운 가능성을 뉴로메카가 함께합니다.Robot.협동로봇과 델타로봇 등 다양한 로봇 라인업을 통해 생산성 향상과 원가 절감 효과를 기대할 수 있으며 동시에 산업재해 고민도 해결할 수 있습니다.Video.동영상 보기동영상 보기01:20동영상 보기동영상 보기02:17동영상 보기동영상 보기01:44동영상 보기동영상 보기01:19동영상 보기동영상 보기03:48동영상 보기동영상 보기02:08동영상 보기동영상 보기04:39Post.News.7일 전뉴로메카, SK네트웍스서비스와 로봇 공급 총판 계약...\"기간은 2년, 이후엔 갱신\"12월 13일지능로봇 리빙랩 기반 인재육성 나선다…수원시 협약11월 10일교촌 치킨을 뉴로메카 로봇이 만든다12345Robot as a Tool |\\xa0Robot as a Service |\\xa0Robots for Every Workplace\\u200b(주)뉴로메카\\xa0 \\xa0 \\xa0서울특별시 성동구 아차산로 78, 에코넷센터 (04782) \\xa0 \\xa0 TEL : 1661-0773\\xa0 \\xa0 \\xa0영업 : sales@neuromeka.com\\xa0 \\xa0 \\xa0마케팅/홍보 : pr@neuromeka.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9921ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sales@neuromeka.com', 'pr@neuromeka.com']\n"
     ]
    }
   ],
   "source": [
    "email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "emails = re.findall(email_pattern, matches[0])\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a197b4fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "email_addresses = []\n",
    "\n",
    "for a_tag in soup.find_all('a', href=True):\n",
    "    if 'mailto:' in a_tag['href']:\n",
    "        email_addresses.append(a_tag['href'].split(':')[1])\n",
    "\n",
    "for span_tag in soup.find_all('span'):\n",
    "    email_addresses.append(span_tag.get_text())\n",
    "\n",
    "# 결과 출력\n",
    "# print(email_addresses)\n",
    "for i in email_addresses:\n",
    "    matches = re.findall(email_pattern, i)\n",
    "    print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56066e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " 'This is the first paragraph.',\n",
       " 'This is the second paragraph.',\n",
       " 'This is the third paragraph.',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 예시로 사용할 HTML\n",
    "html = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <p>This is the first paragraph.</p>\n",
    "    <p>This is the second paragraph.</p>\n",
    "    <p>This is the third paragraph.</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# BeautifulSoup 객체 생성\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 모든 텍스트 가져오기\n",
    "all_text = soup.get_text()\n",
    "\n",
    "all_text.split('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
